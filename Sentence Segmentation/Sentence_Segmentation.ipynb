{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We divide the text into sentences, using the sents tool,\n",
    "which divides the long sentence into specific sentences\n",
    "\"\"\"\n",
    "\n",
    "doc1 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc1.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# You can also find out if a specific word is the beginning of a sentence or not like this:\n",
    "\n",
    "print(doc1[1].is_sent_start)\n",
    "print(doc1[0].is_sent_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If we want to use a specific sentence, it is not correct to write it like this:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdoc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# If we want to use a specific sentence, it is not correct to write it like this:\n",
    "print(doc1.sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the first sentence."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because it's not a list, but like this\n",
    "list(doc1.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent for sent in doc1.sents]\n",
    "doc_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "# Each word can be examined separately to determine which one begins the sentence like this:\n",
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is another sentence."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n",
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n",
      "True This\n",
      "False is\n",
      "False a\n",
      "False sentence\n",
      "False .\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n",
    "for token in doc2:\n",
    "    print(token.is_sent_start, ''+token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# It is also possible to make the library change its behavior in dividing sentences, so if we have a sentence here\n",
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "It will give us an inappropriate division, as we want it to be divided on the basis of semi-column;\n",
    "You can specify a specific letter to perform the division using it like this:\n",
    "\"\"\"\n",
    "from spacy.language import Language\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \";\":\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"set_custom_boundaries\", before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'set_custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "10 \n",
      "Thomas Gradgrind, sir.\n",
      "--------------------\n",
      "A man of realities.\n",
      "--------------------\n",
      "A man of facts and calculations.\n",
      "--------------------\n",
      "A man who \n",
      "proceeds upon the principle that two and two are four, and nothing over, and who is not \n",
      "to be talked into allowing for anything over.\n",
      "--------------------\n",
      "Thomas Gradgrind, sir—peremptorily \n",
      "Thomas—Thomas Gradgrind.\n",
      "--------------------\n",
      "With a rule and a pair of scales, and the multiplication \n",
      "table always in his pocket, sir, ready to weigh and measure any parcel of human nature, \n",
      "and tell you exactly what it comes to.\n",
      "--------------------\n",
      "It is a mere question of figures, a case of simple \n",
      "arithmetic.\n",
      "--------------------\n",
      "You might hope to get some other nonsensical belief into the head of \n",
      "George Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all \n",
      "supposititious, non-existent persons), but into the head of Thomas Gradgrind—no, sir!\n",
      "--------------------\n",
      "In such terms Mr. Gradgrind always mentally introduced himself, whether to his private \n",
      "circle of acquaintance, or to the public in general.\n",
      "--------------------\n",
      "In such terms, no doubt, substituting \n",
      "the words ‘boys and girls,’ for ‘sir,’ Thomas Gradgrind now presented Thomas Gradgrind \n",
      "to the little pitchers before him, who were to be filled so full of facts.\n",
      "--------------------\n",
      "Indeed, as he eagerly sparkled at them from the cellarage before mentioned, he \n",
      "seemed a kind of cannon loaded to the muzzle with facts, and prepared to blow them \n",
      "clean out of the regions of childhood at one discharge.\n",
      "--------------------\n",
      "He seemed a galvanizing \n",
      "apparatus, too, charged with a grim mechanical substitute for the tender young \n",
      "imaginations that were to be stormed away.\n",
      "--------------------\n",
      "‘Girl number twenty,’ said Mr. Gradgrind, squarely pointing with his square forefinger, ‘I \n",
      "don’t know that girl.\n",
      "--------------------\n",
      "Who is that girl?’ \n",
      "11\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Here, the tokenize_sent tool from the nltk library is used for the same task\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = ''' \n",
    "10 \n",
    "Thomas Gradgrind, sir. A man of realities. A man of facts and calculations. A man who \n",
    "proceeds upon the principle that two and two are four, and nothing over, and who is not \n",
    "to be talked into allowing for anything over. Thomas Gradgrind, sir—peremptorily \n",
    "Thomas—Thomas Gradgrind. With a rule and a pair of scales, and the multiplication \n",
    "table always in his pocket, sir, ready to weigh and measure any parcel of human nature, \n",
    "and tell you exactly what it comes to. It is a mere question of figures, a case of simple \n",
    "arithmetic. You might hope to get some other nonsensical belief into the head of \n",
    "George Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all \n",
    "supposititious, non-existent persons), but into the head of Thomas Gradgrind—no, sir! \n",
    "In such terms Mr. Gradgrind always mentally introduced himself, whether to his private \n",
    "circle of acquaintance, or to the public in general. In such terms, no doubt, substituting \n",
    "the words ‘boys and girls,’ for ‘sir,’ Thomas Gradgrind now presented Thomas Gradgrind \n",
    "to the little pitchers before him, who were to be filled so full of facts. \n",
    "Indeed, as he eagerly sparkled at them from the cellarage before mentioned, he \n",
    "seemed a kind of cannon loaded to the muzzle with facts, and prepared to blow them \n",
    "clean out of the regions of childhood at one discharge. He seemed a galvanizing \n",
    "apparatus, too, charged with a grim mechanical substitute for the tender young \n",
    "imaginations that were to be stormed away. \n",
    "‘Girl number twenty,’ said Mr. Gradgrind, squarely pointing with his square forefinger, ‘I \n",
    "don’t know that girl. Who is that girl?’ \n",
    "11 \n",
    "''' \n",
    "for s in sent_tokenize(EXAMPLE_TEXT):\n",
    "    print(s)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' \\n10 \\nThomas Gradgrind, sir.',\n",
       " 'A man of realities.',\n",
       " 'A man of facts and calculations.',\n",
       " 'A man who \\nproceeds upon the principle that two and two are four, and nothing over, and who is not \\nto be talked into allowing for anything over.',\n",
       " 'Thomas Gradgrind, sir—peremptorily \\nThomas—Thomas Gradgrind.',\n",
       " 'With a rule and a pair of scales, and the multiplication \\ntable always in his pocket, sir, ready to weigh and measure any parcel of human nature, \\nand tell you exactly what it comes to.',\n",
       " 'It is a mere question of figures, a case of simple \\narithmetic.',\n",
       " 'You might hope to get some other nonsensical belief into the head of \\nGeorge Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all \\nsupposititious, non-existent persons), but into the head of Thomas Gradgrind—no, sir!',\n",
       " 'In such terms Mr. Gradgrind always mentally introduced himself, whether to his private \\ncircle of acquaintance, or to the public in general.',\n",
       " 'In such terms, no doubt, substituting \\nthe words ‘boys and girls,’ for ‘sir,’ Thomas Gradgrind now presented Thomas Gradgrind \\nto the little pitchers before him, who were to be filled so full of facts.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also there is a punksentencetokenizer tool in nltk to split sentences\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(EXAMPLE_TEXT)\n",
    "tokenized = custom_sent_tokenizer.tokenize(EXAMPLE_TEXT)\n",
    "tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "هذه هي الجملة الأولي ,.\n",
      "هذه هي الجملة الثانية , والجملة الثالثة\n"
     ]
    }
   ],
   "source": [
    "# But the performance of these tools in the Arabic language is not good\n",
    "doc1 = nlp('هذه هي الجملة الأولي ,. هذه هي الجملة الثانية , والجملة الثالثة')\n",
    "\n",
    "for sent in doc1.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[2].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[هذه هي الجملة الأولي ,., هذه هي الجملة الثانية , والجملة الثالثة]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent for sent in doc1.sents] \n",
    "doc_sents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.') \n",
    "for token in doc2: \n",
    "    print(token.is_sent_start, ' '+token.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "يشكل الذكاء الاصطناعي تحديا والهاما لعلم الفلسفة ؛ لزعمه القدرة على إعادة خلق قدرات العقل البشري\n",
      "وكمارو يحيي الناس\n",
      "هل هناك حدود لمدى ذكاء الآلات؟ هل هناك فرق جوهري بين الذكاء البشري والذكاء الاصطناعي؟ وهل يمكن أن يكون \n",
      " .للآلة عقل ووعي؟ عدد قليل من أهم الإجابات على هذه الأسئلة ترد أدناه\n",
      " \"آلات الحساب والذكاء \"قانون تورنغ\n",
      "إذا كان الجهاز يعمل بذكاء يضاهي الإنسان، إذافذكائه يماثل ذكاء الإنسان.\n",
      "----------------------\n",
      "تفيد نظرية آلان تورنغ أنه، في نهاية المطاف، لا \n",
      " .يسعنا إلا أن نحكم على ذكاء الآلة بناء على أدائها.\n",
      "----------------------\n",
      "هذه النظرية تشكل أساسا لاختبار تورنغ\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_TEXT = ''' \n",
    "يشكل الذكاء الاصطناعي تحديا والهاما لعلم الفلسفة ؛ لزعمه القدرة على إعادة خلق قدرات العقل البشري\n",
    "وكمارو يحيي الناس\n",
    "هل هناك حدود لمدى ذكاء الآلات؟ هل هناك فرق جوهري بين الذكاء البشري والذكاء الاصطناعي؟ وهل يمكن أن يكون \n",
    " .للآلة عقل ووعي؟ عدد قليل من أهم الإجابات على هذه الأسئلة ترد أدناه\n",
    " \"آلات الحساب والذكاء \"قانون تورنغ\n",
    "إذا كان الجهاز يعمل بذكاء يضاهي الإنسان، إذافذكائه يماثل ذكاء الإنسان. تفيد نظرية آلان تورنغ أنه، في نهاية المطاف، لا \n",
    " .يسعنا إلا أن نحكم على ذكاء الآلة بناء على أدائها. هذه النظرية تشكل أساسا لاختبار تورنغ\n",
    "''' \n",
    "for s in sent_tokenize(EXAMPLE_TEXT) : \n",
    " print(s) \n",
    " print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahmed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
